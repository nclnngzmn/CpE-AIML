{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58033_ProblemSet_Tyche.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1CcqZO6kqBs0Z40SLxdQe5Xc4EujqJi0G\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fte_zsqVdp8R"
      },
      "source": [
        "# Topic02a : Prelim Problem Set I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcY5oJ5eFxA"
      },
      "source": [
        "## Case 1\n",
        "Represent the following representations into its vectorized form using LaTeX.\n",
        "> **Problem 1.a. System of Linear Equations**\n",
        "$$\n",
        "\\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        -y+z=\\frac{1}{32}\\\\ \n",
        "        \\frac{1}{2}x -2y=0 \\\\\n",
        "        -x + \\frac{3}{7}z=\\frac{4}{5}\n",
        "    \\end{array}\n",
        "\\right. $$\n",
        "> **Problem 1.b. Linear Combination**\n",
        "$$  \\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n",
        "> **Problem 1.c. Scenario**\n",
        ">\n",
        ">A conference has 200 student attendees, 45 professionals, and has 15 members of the panel. There is a team of 40 people on the organizing committee. Represent the *percent* composition of each *attendee* type of the conference in matrix form.\n",
        "\n",
        "Express your answers in LaTeX in the answer area.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b8gApGpukLP"
      },
      "source": [
        "import numpy as np\n",
        "import math \n",
        "from numpy import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4nVfsGrslQk"
      },
      "source": [
        "### **Problem 1.a: System of Linear Equations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV10UPTpehEf"
      },
      "source": [
        "$$ A = \\begin{bmatrix} 0 & -1 & 1 &  \\frac {1}{32} \\\\ \\frac {1}{2} & -2 &  0 & 0 \\\\ -1 & 0 & \\frac {3}{7} &  \\frac {4}{5} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXKL5UW4s7uV"
      },
      "source": [
        "### **Problem 1.b: Linear Combination**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnzuTF8LhEyo"
      },
      "source": [
        "$$ B = \\begin{bmatrix} \\sin{(\\theta)} \\\\ \\cos{(\\theta)} \\\\ - \\csc{(2\\theta)} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qZeut1RtKj3"
      },
      "source": [
        "### **Problem 1.c: Scenario**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BLFbRgzwrTC"
      },
      "source": [
        "$$Percentage = \\frac{No. of\\:Attendee\\:type \\times 100}{Total\\:Number\\:of\\:Attendees}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRxtP1iSygXr"
      },
      "source": [
        "$$Students = \\frac{200 \\times 100}{300} = 66.67\\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqR5qpipzId5"
      },
      "source": [
        "$$Professionals = \\frac{45 \\times 100}{300} = 15.00\\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdNFa7izVU1"
      },
      "source": [
        "$$Panel\\:Members = \\frac{15 \\times 100}{300} = 13.33\\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVLCzsmyz3tt"
      },
      "source": [
        "$$Organizing\\:Committee = \\frac{40 \\times 100}{300} = 5.00\\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAGjBchFAHQS"
      },
      "source": [
        "###<center>**Matrix form of percentage composition of each attendee type**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seX93li8nxg_"
      },
      "source": [
        "$$ Attendees = \\begin{bmatrix} \n",
        "66.67\\% \\\\ \n",
        "15.00\\% \\\\ \n",
        "13.33\\% \\\\ \n",
        "5.00\\% \n",
        "\\end{bmatrix} $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvb1MGs9QNVt"
      },
      "source": [
        "# Case 2\n",
        "> **Problem 2.a: Vector Magnitude**\n",
        "\n",
        ">The magnitude of a vector is usually computed as:\n",
        "$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n",
        "Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n",
        "Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n",
        "\n",
        "> **Problem 2.b: Angle Between Vectors**\n",
        "\n",
        "> Inner products can also be related to the Law of Cosines. The property suggests that:\n",
        "$$u\\cdot v = ||u||\\cdot||v||\\cos(\\theta)$$\n",
        "Whereas $u$ and $v$ are vectors that have the same sizes and $\\theta$ is the angle between $u$ and $v$.\n",
        "\n",
        "> Explain the behavior of the dot product when the two vectors are perpendicular and when they are parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh_aJKVHuFKB"
      },
      "source": [
        "### **Problem 2.a: Vector Magnitude**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6rkh597VVJ5"
      },
      "source": [
        "An inner product space makes a <b>norm/ length</b>, that is, a notion of length of a vector.\n",
        "\n",
        "<br>Let $ V $ be an inner product space and let $v \\in V $. The <b>norm/length</b> of $v$ is denoted $||v||$ and is defined by\n",
        "\n",
        "$$ ||v|| = \\sqrt{\\langle v,v \\rangle} $$\n",
        "\n",
        "<i>the square root is defined by the property (i) of the inner product.</i>\n",
        "\n",
        "\n",
        "<br><b><u>Example</b></u>: Find $||vect||$ where,\n",
        "\n",
        "$$ vect = \\begin{bmatrix} 2 & 4 \\\\ -3 & 7 \\end{bmatrix} $$\n",
        "\n",
        "<br><b><u>Solution</b></u>:\n",
        "\n",
        "$$ ||vect|| = \\sqrt{\\langle vect,vect \\rangle} $$  \n",
        "\n",
        "$$ = \\sqrt{\\langle\\begin{bmatrix} 2 & 4 \\\\ -3 & 7 \\end{bmatrix}\\rangle,\\langle\\begin{bmatrix} 2 & 4 \\\\ -3 & 7 \\end{bmatrix}\\rangle} $$\n",
        "\n",
        "$$ = \\sqrt{(2)(2) + (4)(4) + (-3)(-3) + (7)(7)} $$\n",
        "\n",
        "$$ = \\sqrt{4 + 16 + 9 + 49} $$\n",
        "\n",
        "$$ vect = \\sqrt{78} \\space or \\space 8.831760866327848 $$\n",
        "\n",
        "<br> Putting this into code would be,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tfuqfQKaJwm",
        "outputId": "ec22eb7f-3b33-4da7-9db5-92f6c046f814"
      },
      "source": [
        "vect = np.array([2,4,-3,7])\n",
        "vect_2 = np.array([2,4,-3,7])\n",
        "\n",
        "answer = np.matmul(vect,vect_2)\n",
        "answer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqCUGvsSgwX7",
        "outputId": "15a27c39-8788-4580-e790-5202c6fa68c5"
      },
      "source": [
        "magnitude = np.sqrt(np.matmul(vect,vect_2))\n",
        "print('The magnitude is the square root of', answer, 'or', magnitude)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The magnitude is the square root of 78 or 8.831760866327848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-J7FOxruKnq"
      },
      "source": [
        "### **Problem 2.b: Angle Between Vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71F3ag_DKtqw"
      },
      "source": [
        "<br> The <b>dot product</b> is a method for determining when two vectors are perpendicular and it will give another method for determining when two vectors are parallel. The term <b>orthogonal</b> is also used in place of perpendicular.\n",
        "\n",
        "<br> If two vectors are <b>orthogonal (perpendicular)</b>, then, the angle between them is 90 degrees. From the Law of Cosines theorem, this tells that if two vectors are orthogonal then,\n",
        "\n",
        "$$ u\\cdot v=0$$\n",
        "\n",
        "<br> With that being said, two vectors are considered to be orthogonal if their dot product <b>equals to 0</b>.\n",
        "\n",
        "<br> Additionally, if two vectors are <b>parallel</b>, then the angle between them is either 0 degrees—pointing in the same direction, or 180 degrees—pointing in the opposite direction. Again, using the Law of Cosine theorem, this would mean that one of the following would have to be <i>true</i>.\n",
        "\n",
        "$$ u\\cdot v=||u||\\cdot||v||\\space(\\theta=0^\\circ)$$ $$OR$$ $$ u\\cdot v=-||u||\\cdot||v||\\space(\\theta=180^\\circ)$$\n",
        "\n",
        "<b><u>Example 1</u></b>:\n",
        "$$ u=\\langle 3,4 \\rangle, v=\\langle -8,6 \\rangle $$\n",
        "\n",
        " <b><u>Solution</u></b>:\n",
        "$$ \\langle 3,4 \\rangle\\space\\cdot\\langle -8,6 \\rangle $$\n",
        "$$ = (3\\times(-8))+4\\times6 $$\n",
        "$$ =-24+24 $$\n",
        "$$ =0 $$\n",
        "\n",
        "Therefore, this makes the vector <b>perpendicular</b>.\n",
        "\n",
        "<br><b><u>Example 2</u></b>:\n",
        "$$ u=\\langle-9,18\\rangle, v=\\langle-3,6\\rangle $$\n",
        "\n",
        "<br><b><u>Solution</u></b>:\n",
        "$$ u = -3v $$\n",
        "\n",
        "Making the vector <b>parallel</b>:\n",
        "$$ 3\\langle-3,6\\rangle=\\langle-9,18\\rangle $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cH8JpkBj1xS"
      },
      "source": [
        "# Case 3\n",
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8jJV9-qyFy"
      },
      "source": [
        "> **Problem 3.a: Matrix Equivalences**\n",
        "\n",
        "> In Eq. 1, $z$ can also be solved as $X \\cdot \\theta$ which is the vectorized form of $x^{(i)}\\theta^{(i)}$. However, it can also be expressed as $\\theta^T\\cdot X$. Prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ in this case.\n",
        "\n",
        "> **Problem 3.b: Matrix Shapes**\n",
        "\n",
        "> Determine the shape of $h_\\theta$ if $X$ has a shape of $(300,5)$.\n",
        "\n",
        "> **Problem 3.c: Vectorization**\n",
        "\n",
        "> Express $J(\\theta)$ into its vectorized form.\n",
        "\n",
        "> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n",
        "\n",
        "> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n",
        "> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7dtZmrVvJyB"
      },
      "source": [
        "### **Problem 3.a: Matrix Equivalences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAVqU7ROi2tt"
      },
      "source": [
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{ ,} \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "$$X \\cdot\\theta = \\begin{bmatrix} \n",
        "— (x^{(1)})^T\\theta— \\\\ \n",
        "— (x^{(2)})^T\\theta— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T\\theta— \\\\\n",
        "\\end{bmatrix} \\ $$\n",
        "\n",
        "$$\\theta^T\\cdot\\ X = \n",
        "\\begin{bmatrix} \n",
        "\\\\— \\theta^T(x^{(1)} —) \\\\ \n",
        "\\\\— \\theta^T(x^{(2)} —) \\\\\n",
        "\\vdots\n",
        "\\\\— \\theta^T(x^{(m)} — ) \\\\\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "\n",
        "using element-wise multiplication:\n",
        " $$X \\cdot\\theta = \\theta^T\\cdot\\ X $$  \n",
        "$$[(x^{(1)})^T\\theta^{(1)} + (x^{(2)})^T\\theta^{(2)}...+(x^{(m)})^T\\theta^{(m)}] = [(x^{(1)})^T\\theta^{(1)} + (x^{(2)})^T\\theta^{(2)}...+(x^{(m)})^T\\theta^{(m)}] $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0aSozrAdqoU"
      },
      "source": [
        "### **Problem 3.b: Matrix Shapes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAZplEqvxmh3"
      },
      "source": [
        "$$ X = \\begin{bmatrix} a^1 & a^2 & a^3 & a^4 & a^5 \\\\ a^6 & a^7 & a^8 & a^9 & a^{10} \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\  a^{296} & a^{297} & a^{298} & a^{299} & a^{300} \\end{bmatrix} \\text{ , } \\theta = \\begin{bmatrix} \n",
        " (\\theta^1) \\\\ \n",
        " (\\theta^2) \\\\\n",
        "\\vdots \\\\\n",
        " (\\theta^k) \\\\\n",
        "\\end{bmatrix} \\ $$\n",
        "\n",
        "The sigmoid function definition is:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "The process can be written with matrix operation:\n",
        "$$ z = X \\cdot\\theta $$\n",
        "\n",
        "$$ h_\\theta(x) = g( X \\cdot\\theta)$$\n",
        "\n",
        "\n",
        "$$ h_\\theta(x) = g(z) $$\n",
        "\n",
        "After applying multiplication between $(k \\cdot 1)$ and $(m\\cdot k)$ dimension we get a number z , then the z is passed to sigmoid function and we will have the final result of $h_\\theta(x)$. The equation can be merged into one therefore the matrix shape of the $ h_\\theta(x)$ would be the same as the matrix X.\n",
        "$$ h_\\theta(x) = \\begin{bmatrix} \\theta^1(a) & \\theta^2(a) & \\theta^3(a) & \\theta^4(a) & \\theta^5(a)\\\\ \\theta^6(a) & \\theta^7(a) & \\theta^8(a) & \\theta^9(a) & \\theta^{10}(a) \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\  \\theta^{296}(a) & \\theta^{297}(a) & \\theta^{298}(a) & \\theta^{299}(a) & \\theta^{300}(a) \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4EWGXkqvaMw"
      },
      "source": [
        "### **Problem 3.c: Vectorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXFEssLcCp0-"
      },
      "source": [
        "The partial derivatives of $(\\theta_j)$\n",
        "\n",
        "$$\\begin{bmatrix} \n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_0} \\\\ \n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_1} \\\\\n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_2} \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial{J}}{\\partial{\\theta}_n} \\\\\n",
        "\\end{bmatrix} = \n",
        "\\frac{1}{m}\n",
        "\\begin{bmatrix} \n",
        "\\sum^{m}_{i=1} [ -y^{(i)} \\log (h_{\\theta} (x^{(i)})) - (1-y^{(i)}) \\log (1-h_{\\theta}(x^{(i)}))] \\\\\n",
        "\\sum^{m}_{i=1} [ -y^{(i)} \\log (h_{\\theta} (x^{(i)})) - (1-y^{(i)}) \\log (1-h_{\\theta}(x^{(i)}))] \\\\ \n",
        "\\sum^{m}_{i=1} [ -y^{(i)} \\log (h_{\\theta} (x^{(i)})) - (1-y^{(i)}) \\log (1-h_{\\theta}(x^{(i)}))] \\\\ \n",
        "\\vdots \\\\\n",
        "\\sum^{m}_{i=1} [ -y^{(i)} \\log (h_{\\theta} (x^{(i)})) - (1-y^{(i)}) \\log (1-h_{\\theta}(x^{(i)}))] \\\\ \n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "Since the partial derivatives were expressed, the gradient vector is formed as:\n",
        "$$\n",
        "\\frac{\\partial{J}(\\theta)}{\\partial{\\theta}_0} =\n",
        "\\frac{1}{m}\n",
        "\\sum\\limits_{i=1}^m (h_0(x^{(i)})-y^{(i)})x^{(i)}_j \n",
        "$$\n",
        "Therefore the vectorized form of $J(\\theta)$ is: \n",
        "$$\n",
        "\\\\=\\frac{1}{m}X^T(h_\\theta(x)-y))\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zB6io0vvgfA"
      },
      "source": [
        "### **Problem 4.c: Computational Programming (Also Laboratory 2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shQtTbM7vlwC"
      },
      "source": [
        "class LRegression():\n",
        "  def __init__(self, X_array, y_GndTruth, thetaVector):\n",
        "    self.X_array = X_array\n",
        "    self.y_GndTruth = y_GndTruth\n",
        "    self.thetaVector = thetaVector\n",
        "  \n",
        "  def getVectorMagnitude(self):\n",
        "    magnitude = np.linalg.norm(self.thetaVector)\n",
        "    return magnitude\n",
        "  \n",
        "  def getZ(self): #Eq. 3.1\n",
        "    self.z = np.dot(self.X_array, self.thetaVector)\n",
        "    return self.z\n",
        "\n",
        "  def getActivation (self): #Eq. 3.2 & 3.3\n",
        "    self.activation = 1/(1+np.exp(self.z))\n",
        "    return self.activation\n",
        "\n",
        "  def getLoss(self): #Eq. 3.4\n",
        "    m = self.y_GndTruth.shape[0]\n",
        "    yt = self.y_GndTruth.transpose()\n",
        "\n",
        "    lossEq= (-1*yt)*(np.log(self.activation)) - ((1-self.y_GndTruth).transpose())*(np.log(1-self.activation))\n",
        "    self.J = (1/m)*lossEq\n",
        "    return self.J"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLju9EF6TMMC"
      },
      "source": [
        "X = np.array([[1,2,3],\n",
        "              [1,2,3],\n",
        "              [4,5,6],])\n",
        "m = X.shape[1]\n",
        "theta = np.random.normal(0, 1, size=(m, 1))\n",
        "y = np.random.randint(0,2, size=(m,1))\n",
        "Regression = LRegression(X, y, theta)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8G1Pi_xrwtb",
        "outputId": "3d9b4df8-adb7-435a-9220-19fd822c7cef"
      },
      "source": [
        "Regression.getVectorMagnitude()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0716158574454309"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBFAIqdfbO23",
        "outputId": "ba506fc9-54ee-4a65-b4e3-de8872143775"
      },
      "source": [
        "Regression.getZ()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.71621582],\n",
              "       [2.71621582],\n",
              "       [7.75637269]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1nz6rw0bXU7",
        "outputId": "d28403f5-8e87-4fc0-e0e8-cd683e31b68f"
      },
      "source": [
        "Regression.getActivation()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06202325],\n",
              "       [0.06202325],\n",
              "       [0.00042782]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEaG4Cq6bdl6",
        "outputId": "8e3b4dc3-0db0-4ac3-ee05-678205b92d04"
      },
      "source": [
        "Regression.getLoss()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.26748645e-01, 2.13433730e-02, 2.13433730e-02],\n",
              "       [9.26748645e-01, 2.13433730e-02, 2.13433730e-02],\n",
              "       [2.58560020e+00, 1.42638237e-04, 1.42638237e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
